{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === CONFIG ===\n",
    "DATA_DIR = \"/tf/rahman/NCH_Sleep_Data_Bank/data\"\n",
    "ECG_CHANNEL = \"ECG EKG2-EKG\"     # Primary ECG channel name\n",
    "ECG_CHANNEL2 = \"ECG LA-RA\"       # Backup ECG channel name\n",
    "RANDOM_SEED = 42                 # For reproducibility\n",
    "\n",
    "# === COLLECT RECORDS ===\n",
    "records = []\n",
    "for file in os.listdir(DATA_DIR):\n",
    "    if file.endswith(\".edf\"):\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        edf_path = os.path.join(DATA_DIR, base_name + \".edf\")\n",
    "        annot_path = os.path.join(DATA_DIR, base_name + \".annot\")\n",
    "        if os.path.exists(annot_path):\n",
    "            records.append(base_name)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Annotation missing for {base_name}, skipping.\")\n",
    "\n",
    "# === SPLIT RECORDS ===\n",
    "train_records, temp_records = train_test_split(records, test_size=0.2, random_state=RANDOM_SEED)\n",
    "val_records, test_records = train_test_split(temp_records, test_size=0.5, random_state=RANDOM_SEED)\n",
    "\n",
    "splits = {\n",
    "    'train': train_records,\n",
    "    'val': val_records,\n",
    "    'test': test_records\n",
    "}\n",
    "\n",
    "# === OUTPUT STRUCTURE ===\n",
    "data = {\n",
    "    'train': {'segments': [], 'labels': []},\n",
    "    'val': {'segments': [], 'labels': []},\n",
    "    'test': {'segments': [], 'labels': []}\n",
    "}\n",
    "\n",
    "# === PROCESS RECORDS BY SPLIT ===\n",
    "for split_name, record_list in splits.items():\n",
    "    print(f\"\\nüîÑ Processing {split_name.upper()} set with {len(record_list)} records...\")\n",
    "    for base_name in record_list:\n",
    "        edf_path = os.path.join(DATA_DIR, base_name + \".edf\")\n",
    "        annot_path = os.path.join(DATA_DIR, base_name + \".annot\")\n",
    "        \n",
    "        try:\n",
    "            # Load EDF\n",
    "            raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "\n",
    "            # Check available channels and select the appropriate ECG channel\n",
    "            available_channels = raw.ch_names\n",
    "            if ECG_CHANNEL in available_channels:\n",
    "                raw_ecg = raw.copy().pick([ECG_CHANNEL])\n",
    "            elif ECG_CHANNEL2 in available_channels:\n",
    "                raw_ecg = raw.copy().pick([ECG_CHANNEL2])\n",
    "            else:\n",
    "                raise ValueError(f\"No valid ECG channel found in {base_name}. Channels: {available_channels}\")\n",
    "            \n",
    "            sfreq = raw_ecg.info['sfreq']\n",
    "\n",
    "            # Load annotations\n",
    "            annot_df = pd.read_csv(annot_path, sep=\"\\t\", header=None, names=[\"description\", \"onset\", \"duration\"])\n",
    "            sleep_stages = annot_df[annot_df['description'].str.contains(\"Sleep stage\")].reset_index(drop=True)\n",
    "\n",
    "            for _, row in sleep_stages.iterrows():\n",
    "                start_sample = int(row['onset'] * sfreq)\n",
    "                end_sample = int((row['onset'] + row['duration']) * sfreq)\n",
    "\n",
    "                ecg_segment, _ = raw_ecg[:, start_sample:end_sample]\n",
    "                if ecg_segment.shape[1] > 0:\n",
    "                    data[split_name]['segments'].append(ecg_segment[0])\n",
    "                    data[split_name]['labels'].append(row['description'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {base_name}: {e}\")\n",
    "\n",
    "# === FINAL REPORT ===\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"\\nüì¶ {split.upper()} SET:\")\n",
    "    print(f\"   ‚û§ Records: {len(splits[split])}\")\n",
    "    print(f\"   ‚û§ Segments: {len(data[split]['segments'])}\")\n",
    "    print(f\"   ‚û§ Unique Stages: {set(data[split]['labels'])}\")\n",
    "\n",
    "# === OPTIONAL: Save to disk ===\n",
    "# np.savez(\"ecg_segments_split_by_record.npz\",\n",
    "#          X_train=data['train']['segments'], y_train=data['train']['labels'],\n",
    "#          X_val=data['val']['segments'], y_val=data['val']['labels'],\n",
    "#          X_test=data['test']['segments'], y_test=data['test']['labels'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
